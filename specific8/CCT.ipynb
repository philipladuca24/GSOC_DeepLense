{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compact convolutional transformer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sklearn.metrics as skl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle\n",
    "with open('mass_imgs.pkl', 'rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "with open('mass_labels.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split images\n",
    "train_imgs, test_imgs, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.1, shuffle=True)\n",
    "rescale = tf.keras.Sequential([\n",
    "        tf.keras.layers.Rescaling(scale=1 / 255)\n",
    "    ])\n",
    "with tf.device('/cpu:0'):\n",
    "    train_imgs = rescale(train_imgs)\n",
    "    test_imgs = rescale(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "augmenter_func = tf.keras.Sequential(\n",
    "  layers=[\n",
    "        tf.keras.layers.RandomFlip(),\n",
    "        tf.keras.layers.RandomRotation(0.25),\n",
    "        tf.keras.layers.RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)),\n",
    "        tf.keras.layers.RandomTranslation(height_factor=(-0.15,0.15), width_factor=(-0.15,0.15)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def orthogonal_rot(image):\n",
    "    return np.rot90(image, np.random.choice([-1, 0, 1]))\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=orthogonal_rot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting data\n",
    "# augmented_1 = augmenter_func(train_imgs[:25])\n",
    "# augmented_2 = augmenter_func(train_imgs[:25])\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for n in range(25):\n",
    "#     ax = plt.subplot(5, 5, n + 1)\n",
    "#     plt.imshow(augmented_1[n].numpy().astype(\"int\"))\n",
    "#     plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for n in range(25):\n",
    "#     ax = plt.subplot(5, 5, n + 1)\n",
    "#     plt.imshow(augmented_2[n].numpy().astype(\"int\"))\n",
    "#     plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "positional_emb = True\n",
    "conv_layers = 3\n",
    "projection_dim = 128\n",
    "\n",
    "num_heads = 2\n",
    "transformer_units = [\n",
    "    projection_dim,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 2\n",
    "stochastic_depth_rate = 0.1\n",
    "\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "image_size = 150\n",
    "\n",
    "PROJECT_DIM = 2048\n",
    "LATENT_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer class\n",
    "class CCTTokenizer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        pooling_kernel_size=3,\n",
    "        pooling_stride=2,\n",
    "        num_conv_layers=conv_layers,\n",
    "        num_output_channels=[32, 64, 128],\n",
    "        positional_emb=positional_emb,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.conv_model = tf.keras.Sequential()\n",
    "        for i in range(num_conv_layers):\n",
    "            self.conv_model.add(\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    num_output_channels[i],\n",
    "                    kernel_size,\n",
    "                    stride,\n",
    "                    padding=\"valid\",\n",
    "                    use_bias=False,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                )\n",
    "            )\n",
    "            self.conv_model.add(tf.keras.layers.ZeroPadding2D(padding))\n",
    "            self.conv_model.add(\n",
    "                tf.keras.layers.MaxPool2D(pooling_kernel_size, pooling_stride, \"same\")\n",
    "            )\n",
    "\n",
    "        self.positional_emb = positional_emb\n",
    "\n",
    "    def call(self, images):\n",
    "        outputs = self.conv_model(images)\n",
    "        reshaped = tf.reshape(\n",
    "            outputs,\n",
    "            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[-1]),\n",
    "        )\n",
    "        return reshaped\n",
    "\n",
    "    def positional_embedding(self, image_size):\n",
    "        if self.positional_emb:\n",
    "            dummy_inputs = tf.ones((1, image_size, image_size, 1))\n",
    "            dummy_outputs = self.call(dummy_inputs)\n",
    "            sequence_length = tf.shape(dummy_outputs)[1]\n",
    "            projection_dim = tf.shape(dummy_outputs)[-1]\n",
    "\n",
    "            embed_layer = tf.keras.layers.Embedding(\n",
    "                input_dim=sequence_length, output_dim=projection_dim\n",
    "            )\n",
    "            return embed_layer, sequence_length\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochasticdepth\n",
    "class StochasticDepth(tf.keras.layers.Layer):\n",
    "    def __init__(self, drop_prop, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = drop_prop\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (tf.shape(x).shape[0] - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCT backbone\n",
    "# def create_cct_model():\n",
    "\n",
    "#     inputs = tf.keras.layers.Input((150,150,1))\n",
    "\n",
    "#     # Encode patches.\n",
    "#     cct_tokenizer = CCTTokenizer()\n",
    "#     encoded_patches = cct_tokenizer(inputs)\n",
    "\n",
    "#     # Apply positional embedding.\n",
    "#     if positional_emb:\n",
    "#         pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
    "#         positions = tf.range(start=0, limit=seq_length, delta=1)\n",
    "#         position_embeddings = pos_embed(positions)\n",
    "#         encoded_patches += position_embeddings\n",
    "\n",
    "#     # Calculate Stochastic Depth probabilities.\n",
    "#     dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
    "\n",
    "#     # Create multiple layers of the Transformer block.\n",
    "#     for i in range(transformer_layers):\n",
    "#         # Layer normalization 1.\n",
    "#         x1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "\n",
    "#         # Create a multi-head attention layer.\n",
    "#         attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "#             num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "#         )(x1, x1)\n",
    "\n",
    "#         # Skip connection 1.\n",
    "#         attention_output = StochasticDepth(dpr[i])(attention_output)\n",
    "#         x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "#         # Layer normalization 2.\n",
    "#         x3 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(x2)\n",
    "\n",
    "#         # MLP.\n",
    "#         x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "#         # Skip connection 2.\n",
    "#         x3 = StochasticDepth(dpr[i])(x3)\n",
    "#         encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "#     # Apply sequence pooling.\n",
    "#     representation = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "#     attention_weights = tf.nn.softmax(tf.keras.layers.Dense(1)(representation), axis=1)\n",
    "#     weighted_representation = tf.matmul(\n",
    "#         attention_weights, representation, transpose_a=True\n",
    "#     )\n",
    "#     weighted_representation = tf.squeeze(weighted_representation, -2)\n",
    "\n",
    "#     # Create the Keras model.\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=weighted_representation, name='CCT')\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder and decoder for simsiam architecture,\n",
    "#compact convolutional transfromer is included in the encoder\n",
    "def get_encoder():\n",
    "\n",
    "    inputs = tf.keras.layers.Input((150,150,1))\n",
    "\n",
    "    # Encode patches.\n",
    "    cct_tokenizer = CCTTokenizer()\n",
    "    encoded_patches = cct_tokenizer(inputs)\n",
    "\n",
    "    # Apply positional embedding.\n",
    "    if positional_emb:\n",
    "        pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
    "        positions = tf.range(start=0, limit=seq_length, delta=1)\n",
    "        position_embeddings = pos_embed(positions)\n",
    "        encoded_patches += position_embeddings\n",
    "\n",
    "    # Calculate Stochastic Depth probabilities.\n",
    "    dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for i in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        attention_output = StochasticDepth(dpr[i])(attention_output)\n",
    "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(x2)\n",
    "\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        x3 = StochasticDepth(dpr[i])(x3)\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "    # Apply sequence pooling.\n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "    attention_weights = tf.nn.softmax(tf.keras.layers.Dense(1)(representation), axis=1)\n",
    "    weighted_representation = tf.matmul(\n",
    "        attention_weights, representation, transpose_a=True\n",
    "    )\n",
    "    weighted_representation = tf.squeeze(weighted_representation, -2, name=\"backbone_rep\")\n",
    "\n",
    "    # Projection head.\n",
    "    x = tf.keras.layers.Dense(\n",
    "        PROJECT_DIM, use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
    "    )(weighted_representation)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        PROJECT_DIM, use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
    "    )(x)\n",
    "    outputs = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs, name=\"encoder\")\n",
    "\n",
    "def get_predictor():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            # Note the AutoEncoder-like structure.\n",
    "            tf.keras.layers.Input((PROJECT_DIM,)),\n",
    "            tf.keras.layers.Dense(\n",
    "                LATENT_DIM,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            ),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(PROJECT_DIM),\n",
    "        ],\n",
    "        name=\"predictor\",\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def compute_loss(p, z):\n",
    "    z = tf.stop_gradient(z)\n",
    "    p = tf.math.l2_normalize(p, axis=1)\n",
    "    z = tf.math.l2_normalize(z, axis=1)\n",
    "    return -tf.reduce_mean(tf.reduce_sum((p * z), axis=1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simsiam model \n",
    "class SimSiam(tf.keras.Model):\n",
    "    def __init__(self, encoder, predictor, augmenter):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.predictor = predictor\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        ds_one, ds_two = self.augmenter(data), self.augmenter(data)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z1, z2 = self.encoder(ds_one), self.encoder(ds_two)\n",
    "            p1, p2 = self.predictor(z1), self.predictor(z2)\n",
    "            loss = compute_loss(p1, z2) / 2 + compute_loss(p2, z1) / 2\n",
    "\n",
    "        learnable_params = (\n",
    "            self.encoder.trainable_variables + self.predictor.trainable_variables\n",
    "        )\n",
    "        gradients = tape.gradient(loss, learnable_params)\n",
    "        self.optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "simsiam = SimSiam(get_encoder(), get_predictor(), augmenter_func)\n",
    "simsiam.compile(optimizer=tf.keras.optimizers.SGD(0.0001, momentum=0.6))\n",
    "history = simsiam.fit(train_imgs, epochs=14, batch_size=64)\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.grid()\n",
    "plt.title(\"Negative Cosine Similairty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the self supervised model\n",
    "backbone = tf.keras.Model(\n",
    "    simsiam.encoder.input, simsiam.encoder.get_layer('tf.compat.v1.squeeze').output\n",
    ")\n",
    "backbone.save('SS_CCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning the regression model\n",
    "backbone.trainable = False\n",
    "inputs = tf.keras.layers.Input((150,150,1))\n",
    "x = backbone(inputs, training=False)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "linear_model = tf.keras.Model(inputs, outputs, name=\"linear_model\")\n",
    "\n",
    "linear_model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"mean_squared_error\"],\n",
    "    optimizer=tf.keras.optimizers.SGD(0.0001, momentum=0.9),\n",
    ")\n",
    "history = linear_model.fit(\n",
    "    datagen.flow(train_imgs, train_labels, batch_size=256), epochs=10\n",
    ")\n",
    "linear_model.save('FT_CCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate regression\n",
    "eval = linear_model.evaluate(test_imgs, np.array(test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d198aacd62101d4c7e30f088a8298ef86ef907cfe0ab142190ab65cf39c3b802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
