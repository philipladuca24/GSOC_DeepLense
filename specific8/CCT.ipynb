{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compact convolutional transformer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sklearn.metrics as skl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle\n",
    "with open('mass_imgs.pkl', 'rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "with open('mass_labels.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split images\n",
    "train_imgs, test_imgs, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.1, shuffle=True)\n",
    "rescale = tf.keras.Sequential([\n",
    "        tf.keras.layers.Rescaling(scale=1 / 255)\n",
    "    ])\n",
    "with tf.device('/cpu:0'):\n",
    "    train_imgs = rescale(train_imgs)\n",
    "    test_imgs = rescale(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "augmenter_func = tf.keras.Sequential(\n",
    "  layers=[\n",
    "        tf.keras.layers.RandomFlip(),\n",
    "        tf.keras.layers.RandomRotation(0.25),\n",
    "        tf.keras.layers.RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)),\n",
    "        tf.keras.layers.RandomTranslation(height_factor=(-0.15,0.15), width_factor=(-0.15,0.15)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def orthogonal_rot(image):\n",
    "    return np.rot90(image, np.random.choice([-1, 0, 1]))\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=orthogonal_rot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting data\n",
    "# augmented_1 = augmenter_func(train_imgs[:25])\n",
    "# augmented_2 = augmenter_func(train_imgs[:25])\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for n in range(25):\n",
    "#     ax = plt.subplot(5, 5, n + 1)\n",
    "#     plt.imshow(augmented_1[n].numpy().astype(\"int\"))\n",
    "#     plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for n in range(25):\n",
    "#     ax = plt.subplot(5, 5, n + 1)\n",
    "#     plt.imshow(augmented_2[n].numpy().astype(\"int\"))\n",
    "#     plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "positional_emb = True\n",
    "conv_layers = 3\n",
    "projection_dim = 128\n",
    "\n",
    "num_heads = 2\n",
    "transformer_units = [\n",
    "    projection_dim,\n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 2\n",
    "stochastic_depth_rate = 0.1\n",
    "\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "image_size = 150\n",
    "\n",
    "PROJECT_DIM = 2048\n",
    "LATENT_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer class\n",
    "class CCTTokenizer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        pooling_kernel_size=3,\n",
    "        pooling_stride=2,\n",
    "        num_conv_layers=conv_layers,\n",
    "        num_output_channels=[32, 64, 128],\n",
    "        positional_emb=positional_emb,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.conv_model = tf.keras.Sequential()\n",
    "        for i in range(num_conv_layers):\n",
    "            self.conv_model.add(\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    num_output_channels[i],\n",
    "                    kernel_size,\n",
    "                    stride,\n",
    "                    padding=\"valid\",\n",
    "                    use_bias=False,\n",
    "                    activation=\"relu\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                )\n",
    "            )\n",
    "            self.conv_model.add(tf.keras.layers.ZeroPadding2D(padding))\n",
    "            self.conv_model.add(\n",
    "                tf.keras.layers.MaxPool2D(pooling_kernel_size, pooling_stride, \"same\")\n",
    "            )\n",
    "\n",
    "        self.positional_emb = positional_emb\n",
    "\n",
    "    def call(self, images):\n",
    "        outputs = self.conv_model(images)\n",
    "        reshaped = tf.reshape(\n",
    "            outputs,\n",
    "            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[-1]),\n",
    "        )\n",
    "        return reshaped\n",
    "\n",
    "    def positional_embedding(self, image_size):\n",
    "        if self.positional_emb:\n",
    "            dummy_inputs = tf.ones((1, image_size, image_size, 1))\n",
    "            dummy_outputs = self.call(dummy_inputs)\n",
    "            sequence_length = tf.shape(dummy_outputs)[1]\n",
    "            projection_dim = tf.shape(dummy_outputs)[-1]\n",
    "\n",
    "            embed_layer = tf.keras.layers.Embedding(\n",
    "                input_dim=sequence_length, output_dim=projection_dim\n",
    "            )\n",
    "            return embed_layer, sequence_length\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochasticdepth\n",
    "class StochasticDepth(tf.keras.layers.Layer):\n",
    "    def __init__(self, drop_prop, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = drop_prop\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            shape = (tf.shape(x)[0],) + (1,) * (tf.shape(x).shape[0] - 1)\n",
    "            random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            return (x / keep_prob) * random_tensor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCT backbone\n",
    "# def create_cct_model():\n",
    "\n",
    "#     inputs = tf.keras.layers.Input((150,150,1))\n",
    "\n",
    "#     # Encode patches.\n",
    "#     cct_tokenizer = CCTTokenizer()\n",
    "#     encoded_patches = cct_tokenizer(inputs)\n",
    "\n",
    "#     # Apply positional embedding.\n",
    "#     if positional_emb:\n",
    "#         pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
    "#         positions = tf.range(start=0, limit=seq_length, delta=1)\n",
    "#         position_embeddings = pos_embed(positions)\n",
    "#         encoded_patches += position_embeddings\n",
    "\n",
    "#     # Calculate Stochastic Depth probabilities.\n",
    "#     dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
    "\n",
    "#     # Create multiple layers of the Transformer block.\n",
    "#     for i in range(transformer_layers):\n",
    "#         # Layer normalization 1.\n",
    "#         x1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "\n",
    "#         # Create a multi-head attention layer.\n",
    "#         attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "#             num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "#         )(x1, x1)\n",
    "\n",
    "#         # Skip connection 1.\n",
    "#         attention_output = StochasticDepth(dpr[i])(attention_output)\n",
    "#         x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "#         # Layer normalization 2.\n",
    "#         x3 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(x2)\n",
    "\n",
    "#         # MLP.\n",
    "#         x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "#         # Skip connection 2.\n",
    "#         x3 = StochasticDepth(dpr[i])(x3)\n",
    "#         encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "#     # Apply sequence pooling.\n",
    "#     representation = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "#     attention_weights = tf.nn.softmax(tf.keras.layers.Dense(1)(representation), axis=1)\n",
    "#     weighted_representation = tf.matmul(\n",
    "#         attention_weights, representation, transpose_a=True\n",
    "#     )\n",
    "#     weighted_representation = tf.squeeze(weighted_representation, -2)\n",
    "\n",
    "#     # Create the Keras model.\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=weighted_representation, name='CCT')\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder and decoder for simsiam architecture,\n",
    "#compact convolutional transfromer is included in the encoder\n",
    "def get_encoder():\n",
    "\n",
    "    inputs = tf.keras.layers.Input((150,150,1))\n",
    "\n",
    "    # Encode patches.\n",
    "    cct_tokenizer = CCTTokenizer()\n",
    "    encoded_patches = cct_tokenizer(inputs)\n",
    "\n",
    "    # Apply positional embedding.\n",
    "    if positional_emb:\n",
    "        pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
    "        positions = tf.range(start=0, limit=seq_length, delta=1)\n",
    "        position_embeddings = pos_embed(positions)\n",
    "        encoded_patches += position_embeddings\n",
    "\n",
    "    # Calculate Stochastic Depth probabilities.\n",
    "    dpr = [x for x in np.linspace(0, stochastic_depth_rate, transformer_layers)]\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for i in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        attention_output = StochasticDepth(dpr[i])(attention_output)\n",
    "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-5)(x2)\n",
    "\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        x3 = StochasticDepth(dpr[i])(x3)\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "    # Apply sequence pooling.\n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-5)(encoded_patches)\n",
    "    attention_weights = tf.nn.softmax(tf.keras.layers.Dense(1)(representation), axis=1)\n",
    "    weighted_representation = tf.matmul(\n",
    "        attention_weights, representation, transpose_a=True\n",
    "    )\n",
    "    weighted_representation = tf.squeeze(weighted_representation, -2, name=\"backbone_rep\")\n",
    "\n",
    "    # Projection head.\n",
    "    x = tf.keras.layers.Dense(\n",
    "        PROJECT_DIM, use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
    "    )(weighted_representation)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        PROJECT_DIM, use_bias=False, kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
    "    )(x)\n",
    "    outputs = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs, name=\"encoder\")\n",
    "\n",
    "def get_predictor():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            # Note the AutoEncoder-like structure.\n",
    "            tf.keras.layers.Input((PROJECT_DIM,)),\n",
    "            tf.keras.layers.Dense(\n",
    "                LATENT_DIM,\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
    "            ),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(PROJECT_DIM),\n",
    "        ],\n",
    "        name=\"predictor\",\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def compute_loss(p, z):\n",
    "    z = tf.stop_gradient(z)\n",
    "    p = tf.math.l2_normalize(p, axis=1)\n",
    "    z = tf.math.l2_normalize(z, axis=1)\n",
    "    return -tf.reduce_mean(tf.reduce_sum((p * z), axis=1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simsiam model \n",
    "class SimSiam(tf.keras.Model):\n",
    "    def __init__(self, encoder, predictor, augmenter):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.predictor = predictor\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        ds_one, ds_two = self.augmenter(data), self.augmenter(data)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z1, z2 = self.encoder(ds_one), self.encoder(ds_two)\n",
    "            p1, p2 = self.predictor(z1), self.predictor(z2)\n",
    "            loss = compute_loss(p1, z2) / 2 + compute_loss(p2, z1) / 2\n",
    "\n",
    "        learnable_params = (\n",
    "            self.encoder.trainable_variables + self.predictor.trainable_variables\n",
    "        )\n",
    "        gradients = tape.gradient(loss, learnable_params)\n",
    "        self.optimizer.apply_gradients(zip(gradients, learnable_params))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "282/282 [==============================] - 88s 287ms/step - loss: -0.1722\n",
      "Epoch 2/14\n",
      "282/282 [==============================] - 82s 291ms/step - loss: -0.3029\n",
      "Epoch 3/14\n",
      "282/282 [==============================] - 84s 300ms/step - loss: -0.3755\n",
      "Epoch 4/14\n",
      "282/282 [==============================] - 87s 308ms/step - loss: -0.4301\n",
      "Epoch 5/14\n",
      "282/282 [==============================] - 88s 311ms/step - loss: -0.4764\n",
      "Epoch 6/14\n",
      "282/282 [==============================] - 88s 312ms/step - loss: -0.5190\n",
      "Epoch 7/14\n",
      "282/282 [==============================] - 89s 317ms/step - loss: -0.5596\n",
      "Epoch 8/14\n",
      "282/282 [==============================] - 89s 317ms/step - loss: -0.5986\n",
      "Epoch 9/14\n",
      "282/282 [==============================] - 89s 316ms/step - loss: -0.6364\n",
      "Epoch 10/14\n",
      "282/282 [==============================] - 90s 319ms/step - loss: -0.6734\n",
      "Epoch 11/14\n",
      "282/282 [==============================] - 87s 308ms/step - loss: -0.7147\n",
      "Epoch 12/14\n",
      "282/282 [==============================] - 85s 303ms/step - loss: -0.8169\n",
      "Epoch 13/14\n",
      "282/282 [==============================] - 86s 304ms/step - loss: -0.9483\n",
      "Epoch 14/14\n",
      "282/282 [==============================] - 85s 302ms/step - loss: -0.9830\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train model\n",
    "simsiam = SimSiam(get_encoder(), get_predictor(), augmenter_func)\n",
    "simsiam.compile(optimizer=tf.keras.optimizers.SGD(0.0001, momentum=0.6))\n",
    "history = simsiam.fit(train_imgs, epochs=14, batch_size=64)\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.grid()\n",
    "plt.title(\"Negative Cosine Similairty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SS_CCT_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SS_CCT_5\\assets\n"
     ]
    }
   ],
   "source": [
    "#save the self supervised model\n",
    "backbone = tf.keras.Model(\n",
    "    simsiam.encoder.input, simsiam.encoder.get_layer('tf.compat.v1.squeeze').output\n",
    ")\n",
    "backbone.save('SS_CCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 16s 190ms/step - loss: 0.0823 - mean_squared_error: 0.0823\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 13s 189ms/step - loss: 8.3358e-04 - mean_squared_error: 8.3358e-04\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 13s 188ms/step - loss: 7.8860e-04 - mean_squared_error: 7.8860e-04\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 13s 189ms/step - loss: 7.9281e-04 - mean_squared_error: 7.9281e-04\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 14s 190ms/step - loss: 7.8984e-04 - mean_squared_error: 7.8984e-04\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 14s 190ms/step - loss: 7.9082e-04 - mean_squared_error: 7.9082e-04\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 14s 190ms/step - loss: 7.8614e-04 - mean_squared_error: 7.8614e-04\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 14s 196ms/step - loss: 7.8592e-04 - mean_squared_error: 7.8592e-04\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 14s 198ms/step - loss: 7.7940e-04 - mean_squared_error: 7.7940e-04\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 14s 198ms/step - loss: 7.6970e-04 - mean_squared_error: 7.6970e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FT_CCT_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FT_CCT_5\\assets\n"
     ]
    }
   ],
   "source": [
    "#fine tuning the regression model\n",
    "backbone.trainable = False\n",
    "inputs = tf.keras.layers.Input((150,150,1))\n",
    "x = backbone(inputs, training=False)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "linear_model = tf.keras.Model(inputs, outputs, name=\"linear_model\")\n",
    "\n",
    "linear_model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"mean_squared_error\"],\n",
    "    optimizer=tf.keras.optimizers.SGD(0.0001, momentum=0.9),\n",
    ")\n",
    "history = linear_model.fit(\n",
    "    datagen.flow(train_imgs, train_labels, batch_size=256), epochs=10\n",
    ")\n",
    "linear_model.save('FT_CCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 34ms/step - loss: 7.9910e-04 - mean_squared_error: 7.9910e-04\n"
     ]
    }
   ],
   "source": [
    "#evaluate regression\n",
    "eval = linear_model.evaluate(test_imgs, np.array(test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d198aacd62101d4c7e30f088a8298ef86ef907cfe0ab142190ab65cf39c3b802"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
